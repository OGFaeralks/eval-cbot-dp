{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrhYamweCsUB"
      },
      "outputs": [],
      "source": [
        "%pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVh73cZLB3s9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import PreTrainedTokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exg-r_26CwvO"
      },
      "outputs": [],
      "source": [
        "class DatasetFromJSON(Dataset):\n",
        "    def __init__(self, data: List[List[str]], tokenizer: PreTrainedTokenizer, max_length=1024):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_data = []\n",
        "        self.max_length = max_length\n",
        "        for conversation in data:\n",
        "            for i in range(len(conversation) - 1):\n",
        "                input_pair = (conversation[i], conversation[i + 1])\n",
        "                encoded_pair = tokenizer.encode(input_pair[0], input_pair[1], add_special_tokens=True, truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
        "                self.input_data.append(encoded_pair)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.input_data[idx]\n",
        "        return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsgoOKPoCyN8"
      },
      "outputs": [],
      "source": [
        "# This is done to process the medical conversations JSON file\n",
        "def read_and_process_json(file_path: str) -> List[List[str]]:\n",
        "    print(\"Reading...\")\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def train_dialo_gpt(model_name, conversations, output_dir, epochs=1):\n",
        "    print(\"Training...\")\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")) \n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    train_dataset = DatasetFromJSON(conversations, tokenizer)\n",
        "    \n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, \n",
        "        mlm=False,\n",
        "        pad_to_multiple_of=8\n",
        "    )\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=epochs,\n",
        "        per_device_train_batch_size=2,\n",
        "        save_steps=100,\n",
        "        save_total_limit=3,\n",
        "        logging_steps=100,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "    )\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_file = \"./train_data.json\"\n",
        "model_output = \"./models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lg_dk6JDUAm"
      },
      "outputs": [],
      "source": [
        "def train_medical(): \n",
        "    conversations = read_and_process_json(training_file)\n",
        "    train_dialo_gpt(\"microsoft/DialoGPT-large\", conversations, model_output, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UjOEW8REo41"
      },
      "outputs": [],
      "source": [
        "train_medical()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
